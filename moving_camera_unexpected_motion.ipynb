{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_classes = ['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dynamic_classes = {\"person\", \"car\", \"bicycle\", \"dog\", \"cat\", \"ball\", \"motorbike\", \"truck\", \"bus\"}\n",
    "static_classes = {\"chair\", \"table\", \"tvmonitor\", \"bed\", \"refrigerator\", \"pottedplant\", \"toilet\", \"sofa\"}\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define parameters for goodFeaturesToTrack\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "\n",
    "# Initialize YOLO model\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")  # Make sure these paths are correct\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Open the video\n",
    "\n",
    "moving_points_over_time = []  # Track moving optical flow points  # To track object positions per frame\n",
    "\n",
    "heatmap = np.zeros((480, 640), dtype=np.float32)  # adjust to your video resolution\n",
    "cap = cv2.VideoCapture(\"cube.mp4\")\n",
    "\n",
    "# Initialize the previous frame and points for optical flow\n",
    "prev_gray = None\n",
    "prev_points = None\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect objects using YOLO\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # Get the bounding boxes of detected objects\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:  # Minimum confidence threshold\n",
    "                center_x = int(detection[0] * frame.shape[1])\n",
    "                center_y = int(detection[1] * frame.shape[0])\n",
    "                w = int(detection[2] * frame.shape[1])\n",
    "                h = int(detection[3] * frame.shape[0])\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                moving_points_over_time.extend([(a, b) for (a, b) in moved_points])\n",
    "\n",
    "                label = coco_classes[class_id]\n",
    "                color = (0, 255, 255)  # Cyan\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                \n",
    "                # Check for unexpected motion (semantic + tracking)\n",
    "                motion_score = sum(\n",
    "                    1 for (px, py) in moved_points\n",
    "                    if x <= px <= x + w and y <= py <= y + h\n",
    "                )\n",
    "                if label in static_classes and motion_score > 3:\n",
    "                    print(f\"⚠️ Unexpected motion detected in '{label}' at ({x}, {y}) with score: {motion_score}\")\n",
    "\n",
    "                cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "\n",
    "    # If previous points exist, calculate optical flow\n",
    "    if prev_points is not None:\n",
    "        # Calculate optical flow\n",
    "        next_points, status, _ = cv2.calcOpticalFlowPyrLK(prev_gray, gray, prev_points, None)\n",
    "\n",
    "        # Ensure status array matches points\n",
    "        valid_points = next_points[status == 1]\n",
    "        prev_valid_points = prev_points[status == 1]\n",
    "\n",
    "        \n",
    "        \n",
    "        moved_points = []  # Ensure moved_points is defined\n",
    "        # Update heatmap with moving points\n",
    "for (a, b), (c, d) in zip(moved_points, prev_valid_points):\n",
    "            x, y = int(b), int(a)\n",
    "            if 0 <= x < heatmap.shape[0] and 0 <= y < heatmap.shape[1]:\n",
    "                movement = np.sqrt((a - c)**2 + (b - d)**2)\n",
    "                heatmap[x, y] += movement\n",
    "                heatmap[x, y] += 1\n",
    "            \n",
    "        # Visualize tracked points\n",
    "        moved_points = []\n",
    "        for i, (new, old) in enumerate(zip(valid_points, prev_valid_points)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            movement = np.sqrt((a - c)**2 + (b - d)**2)\n",
    "            if movement > 2:  # Threshold to consider the point as \"moving\"\n",
    "                moved_points.append((a, b))\n",
    "                frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 0, 255), -1)  # Red dot for moving points\n",
    "            else:\n",
    "                frame = cv2.circle(frame, (int(a), int(b)), 3, (255, 0, 0), -1)  # Blue dot for stationary points\n",
    "        \n",
    "        # Draw lines between matching points\n",
    "        for i, (new, old) in enumerate(zip(valid_points, prev_valid_points)):\n",
    "            a, b = new.ravel().astype(int)  # Ensure points are integers\n",
    "            c, d = old.ravel().astype(int)  # Ensure points are integers\n",
    "            frame = cv2.line(frame, (a, b), (c, d), (0, 255, 0), 2)\n",
    "\n",
    "        # Now, calculate homography if enough points are valid\n",
    "        if len(valid_points) >= 4:  # At least 4 points are needed for homography\n",
    "            H, _ = cv2.findHomography(prev_valid_points, valid_points, cv2.RANSAC)\n",
    "            # Optionally, you can warp the frame with the homography matrix\n",
    "            height, width = frame.shape[:2]\n",
    "            warped_frame = cv2.warpPerspective(frame, H, (width, height))\n",
    "\n",
    "    # Detect new feature points\n",
    "    prev_points = cv2.goodFeaturesToTrack(gray, mask=None, **feature_params)\n",
    "\n",
    "    # Show the frame with detected optical flow\n",
    "    last_valid_frame = frame.copy()\n",
    "    cv2.imshow('Frame', frame)\n",
    "\n",
    "    # Press 'q' to quit the video display window\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Update previous frame\n",
    "    prev_gray = gray\n",
    "\n",
    "# Release resources and close windows\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Plot object movement trajectory\n",
    "import matplotlib.pyplot as plt\n",
    "if moving_points_over_time:\n",
    "    xs, ys = zip(*moving_points_over_time)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(xs, ys, marker='o', linestyle='-', markersize=3)\n",
    "    plt.title('Moving Points Trajectory')\n",
    "    plt.xlabel('X position')\n",
    "    plt.ylabel('Y position')\n",
    "    plt.grid(True)\n",
    "    plt.gca().invert_yaxis()  # Y-axis inverted to match image coordinates\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Show heatmap of motion intensity\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(heatmap, cmap='hot')\n",
    "plt.title(\"Motion Intensity Heatmap\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
